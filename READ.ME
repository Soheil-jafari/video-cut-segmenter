# ğŸ¬ Spatiotemporal Video Segmentation using Vision Transformers (DINO) + Spectral Clustering

This project implements a self-supervised deep learning pipeline that segments objects or temporal events in videos using **Vision Transformers (ViT)** and **spectral clustering**. Patch-level features are extracted using a pretrained DINO model, and frame-to-frame similarity is analyzed to group visual content without any labels or manual annotations.

---

## ğŸ§  Key Features

- âœ… Patch token extraction using Hugging Faceâ€™s **DINO-ViT**
- âœ… Frame-wise **affinity matrix** construction using cosine similarity
- âœ… **Spectral clustering** to segment coherent regions across time
- âœ… Visual output: frames overlaid with pseudo-object masks
- âœ… Fully modular â€” easy to extend for other video or temporal tasks

---

## ğŸ“ Directory Structure

video-cut-segmenter/
â”œâ”€â”€ extract_frames.py # Extracts frames from video
â”œâ”€â”€ dino_features.py # Extracts ViT patch embeddings
â”œâ”€â”€ build_affinity.py # Builds temporal patch similarity matrix
â”œâ”€â”€ spectral_clustering.py # Performs unsupervised clustering
â”œâ”€â”€ visualize.py # Overlays cluster labels on frames
â”œâ”€â”€ main.py # Orchestrates the full pipeline
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ input_video.mp4 # (optional, if running the code)
â””â”€â”€ samples/ # Manually added sample outputs (screenshots)
â”œâ”€â”€ output_0001.jpg
â”œâ”€â”€ output_0005.jpg
â””â”€â”€ output_0012.jpg

yaml
Copy
Edit

---

## ğŸš€ How to Run (Optional)

If you wish to run the pipeline:

1. Install dependencies:
   ```bash
   pip install -r requirements.txt
Place a short .mp4 video in the project folder and name it:

Copy
Edit
input_video.mp4
Run:

bash
Copy
Edit
python main.py
The output frames will be saved as:

Copy
Edit
output_0000.jpg, output_0001.jpg, ...
ğŸ–¼ï¸ Sample Output
Here are example frames with clustered segmentation overlays:

<img src="samples/output_0001.jpg" width="300"/> <img src="samples/output_0005.jpg" width="300"/>
<img src="samples/output_0012.jpg" width="300"/>

ğŸ“¦ Dependencies
torch, torchvision

transformers (DINO ViT)

opencv-python

matplotlib

scikit-learn

scipy

tqdm

Install them via:

bash
Copy
Edit
pip install -r requirements.txt
ğŸ“Œ Applications
ğŸ”¬ Medical video segmentation (e.g., endoscopy, surgery)

ğŸ§  Unsupervised object tracking and event boundary detection

ğŸ¤– Temporal parsing in robotics and surveillance

ğŸ§ª Research prototyping for CVPR/NeurIPS-style work

ğŸ“š Citation / Inspiration
Vision Transformer backbone: facebook/dino-vitb16

Method inspired by: "VideoCutLER: Surprisingly Simple Unsupervised Video Instance Segmentation" (CVPR 2024)

ğŸ’¡ Author Notes
This repository demonstrates an unsupervised learning approach for understanding videos through patch-based temporal clustering. It was built as part of a research showcase for advanced deep learning applications.

Feel free to clone, build on top of it, or reach out with feedback!

yaml
Copy
Edit

---

Let me know if you want:
- A short academic-style abstract for your GitHub profile
- A polished project description (like a mini paper title + summary)
- Help writing the repository â€œAboutâ€ section for GitHub

Once you upload everything, this will look like a **top-tier PhD project**.
